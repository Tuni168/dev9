{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a295c91-68b6-4236-aeeb-4439124ae950",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_117/1547917104.py\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf_oneway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"311 project (1).ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1IBHQ8TjDA6UKhuow0J_rR_yl-LZhBkWf\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\"\"\"* Import a 311 NYC service request.\"\"\"\n",
    "\n",
    "hr1=pd.read_csv(\"/content/drive/MyDrive/simplilearn/python with data science /project1/311_Service_Requests_from_2010_to_Present.csv\")\n",
    "\n",
    "hr1.head()\n",
    "\n",
    "hr1.describe()\n",
    "\n",
    "hr1.info()\n",
    "\n",
    "hr1.dtypes\n",
    "\n",
    "\"\"\"*first we see what % of missing data in dataset\n",
    "\n",
    "and ploting a values in bar chart\n",
    "\"\"\"\n",
    "\n",
    "hr1.isnull().sum()/len(hr1)*100\n",
    "\n",
    "\"\"\"to visualize number of null values in dataset \n",
    "by ploting bar chart we can see \n",
    "which column has what num of null values \n",
    "\"\"\"\n",
    "\n",
    "hr1.isnull().sum().plot(kind='bar', figsize=(10,5),title = 'missing values')\n",
    "\n",
    "\"\"\"as visible in bar graph many columns has max missing values that contant null\n",
    "\n",
    "second task is to remove not columns  having maximum null values.\n",
    "\"\"\"\n",
    "\n",
    "hr1.keys()\n",
    "\n",
    "un_useble= ['Agency Name','Incident Address','Street Name','Cross Street 1','Cross Street 2','Intersection Street 1',\n",
    "'Intersection Street 2','Address Type','Park Facility Name','Park Borough','School Name',\n",
    "'School Number','School Region','School Code','School Phone Number','School Address','School City',\n",
    "'School State','School Zip','School Not Found','School or Citywide Complaint','Vehicle Type',\n",
    "'Taxi Company Borough','Taxi Pick Up Location','Bridge Highway Name','Bridge Highway Direction',\n",
    "'Road Ramp','Bridge Highway Segment','Garage Lot Name','Ferry Direction','Ferry Terminal Name','Landmark',\n",
    "'X Coordinate (State Plane)','Y Coordinate (State Plane)','Due Date','Resolution Action Updated Date','Community Board','Facility Type']\n",
    "\n",
    "\"\"\"serching a values in status column and visualize what num of tipe values related to which cattegiry by bar chart \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "hr1['Status'].value_counts().plot(kind='bar',alpha=0.6,figsize=(6,10))\n",
    "plt.show()\n",
    "\n",
    "hr1.drop(un_useble, inplace=True, axis=1)\n",
    "hr1= hr1[(hr1['Latitude'].notnull())& (hr1['Longitude'].notnull()) & (hr1['Descriptor'].notnull())]\n",
    "hr1 = hr1[hr1['Status']=='Closed']\n",
    "hr1.drop(['Status'],inplace=True, axis=1)\n",
    "hr1.info()\n",
    "\n",
    "\"\"\"second task \n",
    "changing data type from object to date and time by using date and time module \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "hr1[\"Created Date\"]=pd.to_datetime(hr1['Created Date'])\n",
    "hr1[\"Closed Date\"]=pd.to_datetime(hr1['Closed Date'])\n",
    "\n",
    "hr1.info()\n",
    "\n",
    "\"\"\" add new calumn \"Request_closing_time\" for colepsed time between created date anf closed date \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "hr1['Request_closing_time']=hr1[\"Closed Date\"]-hr1[\"Created Date\"]\n",
    "\n",
    "hr1['Request_closing_time']\n",
    "\n",
    "hr1.info()\n",
    "\n",
    "hr1.columns\n",
    "\n",
    "\"\"\"then again see the % of null values remain in data set \"\"\"\n",
    "\n",
    "hr1.isnull().sum()/len(hr1)*100\n",
    "\n",
    "\"\"\"complain distribution across borough\n",
    "\n",
    "visualizing in pie chart\n",
    "\"\"\"\n",
    "\n",
    "hr1['Borough'].value_counts()\n",
    "\n",
    "colors = ['#639ace','#ca6b39','#7f67ca','#5ba85f','#c360aa','#a7993f','#cc566a']\n",
    "hr1['Borough'].value_counts().plot(kind='pie',autopct='%1.1f%%',\n",
    "                        explode = (0.15, 0, 0, 0,0), startangle=45, shadow=False, colors = colors,\n",
    "                        figsize = (8,6))\n",
    "#plt.legend(title='BOROUGH', loc='upper right', bbox_to_anchor=(1.5,1))\n",
    "plt.axis('equal')\n",
    "plt.title('# complaints distribution across Boroughs (2015)\\n')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "hr1['Request_closing_time'].sort_values()\n",
    "\n",
    "\"\"\"to calculating avarage time  we have to cal aprox time for each values of time\n",
    "\n",
    "and view values of request closing time  in hour (aprox)\n",
    "\"\"\"\n",
    "\n",
    "hr1['Request_Closing_Hours'] = hr1['Request_closing_time'].astype('timedelta64[h]')+1\n",
    "hr1[['Request_closing_time','Request_Closing_Hours']].head()\n",
    "\n",
    "\"\"\"#grouping complaint type and borough based on Request Closing Hour\n",
    "\n",
    "#and taking a visualized look of the data--based on perticular location what type and number of compl. accur at\n",
    "\"\"\"\n",
    "\n",
    "grouped_data = hr1.groupby(['Complaint Type','Borough'])[['Request_Closing_Hours']].mean().unstack()\n",
    "\n",
    "grouped_data.head()\n",
    "\n",
    "\"\"\"#visualizing top 5 complaints in each borough using subplots\"\"\"\n",
    "\n",
    "col_number = 2\n",
    "row_number = 3\n",
    "fig, axes = plt.subplots(row_number,col_number, figsize=(12,8))\n",
    "\n",
    "for i, (label,col) in enumerate(grouped_data.iteritems()):\n",
    "    ax = axes[int(i/col_number), i%col_number]\n",
    "    col = col.sort_values(ascending=True)[:15]\n",
    "    col.plot(kind='barh', ax=ax)\n",
    "    ax.set_title(label)\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "(hr1['Complaint Type'].value_counts()).head(25).plot(kind='bar',\n",
    "                                                    figsize=(10,6),title = 'Most Frequent Complaints in Brooklyn')\n",
    "\n",
    "\"\"\"#doing ANOVA test to check whether the average response time across complaint types is similar or not\n",
    "\n",
    "**h0**= average response time across complaint types is similar\n",
    "if p>0.05\n",
    "\n",
    "ha=average response time across complaint types is not  similar \n",
    "so for proove that we have cheake p value p<0.05\n",
    "\"\"\"\n",
    "\n",
    "data = {}\n",
    "for complaint in hr1['Complaint Type'].unique():\n",
    "    data[complaint] = np.log(hr1[hr1['Complaint Type']==complaint]['Request_Closing_Hours'])\n",
    "\n",
    "data[complaint].head()\n",
    "\n",
    "data.keys()\n",
    "\n",
    "# import f_oneway from scipy.stats library\n",
    "\n",
    "stat, p = f_oneway(data['Noise - Street/Sidewalk'],data['Blocked Driveway'],data['Illegal Parking'],data['Derelict Vehicle'],\n",
    "                   data['Noise - Commercial'])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "if p > 0.05:\n",
    "    print('the average response time across complaint types is similar hence \"fail to reject H0\"')\n",
    "else:\n",
    "    print('the average response time across complaint types is not similar hence \"reject H0\"')\n",
    "\n",
    "\"\"\"checking correlation between location and complaint types\n",
    "\n",
    "to performe corelation test we have all the value in numerical formate so first task is to change cattegorical values to numerical \n",
    "by using getdummies ()\n",
    "\n",
    "then perform a test between location and comp. type\n",
    "\"\"\"\n",
    "\n",
    "corr_test_data = hr1[['Complaint Type','Borough','Longitude','Latitude','City']]\n",
    "\n",
    "corr_test_data['Complaint Type']=pd.get_dummies(corr_test_data['Complaint Type'])\n",
    "corr_test_data['Borough']=pd.get_dummies(corr_test_data['Borough'])\n",
    "corr_test_data['City']=pd.get_dummies(corr_test_data['City'])\n",
    "\n",
    "corr_test_data.corr()\n",
    "\n",
    "\"\"\"view the correlation by using heatmap \n",
    "using seaborn lib \n",
    "\"\"\"\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(corr_test_data.corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad1674-2735-41c6-ae4d-ff91cbb951e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
